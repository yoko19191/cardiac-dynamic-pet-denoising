{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbour2Neighbor Experiment\n",
    "\n",
    "[CVPR 2021: Neighbor2Neighbor: Self-Supervised Denoising from Single Noisy Images](https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Neighbor2Neighbor_Self-Supervised_Denoising_From_Single_Noisy_Images_CVPR_2021_paper.pdf)\n",
    "\n",
    "Key idea: \n",
    "- Blind-spot network(BSN), network learn the mapping between mask pixel(s) and every other pixels\n",
    "- the expect of output identical to clean image when noise mean is zero and i.i.d and there traing data inf.\n",
    "\n",
    "limitation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from module.utils import calculate_metrics, display_image_in_detail, plot_2d_data, timer_decorator, display_4d_image, timer_decorator\n",
    "from module.datasets import load_4d_dicom, save_4d_dicom, restore_data\n",
    "\n",
    "from module.models import UNet2_5D\n",
    "from module.datasets import Nb2NbDataset\n",
    "from module.loss import SSIMLoss, SSIM_MAELoss, SSIM_MSELoss\n",
    "\n",
    "\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load noisy data\n",
    "with h5py.File('./dataset/preprocessed/PT_20p 150_120 OSEM_poisson_0.50_batch.h5', 'r') as f:\n",
    "    noisy_data = f['dataset'][...]\n",
    "    restore_info = json.loads(f['restore_info'][()])\n",
    "    \n",
    "print(f\"Noisy data...{noisy_data.dtype} (shape:{noisy_data.shape}; range:[{np.min(noisy_data)},{np.max(noisy_data)}]; mean:{np.mean(noisy_data)}); std:{np.std(noisy_data)}\")\n",
    "\n",
    "print(restore_info)\n",
    "\n",
    "display_image_in_detail(noisy_data[0, 11, 38], title=\"prepared noisy data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import denoising network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = UNet2_5D(in_channels=3, out_channels=1)\n",
    "model = model.to(device)\n",
    "print(\"The number of parameters of the network is: \",  sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "summary(model, [(1, 192, 192), (1, 192, 192), (1, 192, 192)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. create mask dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def split_tensor(data_tensor):\n",
    "#     \"\"\"split tensor into train, test, vali tensor\n",
    "\n",
    "#     Args:\n",
    "#         data_tensor (_type_): _description_\n",
    "\n",
    "#     Returns:\n",
    "#         _type_: _description_\n",
    "#     \"\"\"\n",
    "#     test_tensor = data_tensor[0:1]\n",
    "    \n",
    "#     rest_tensor = data_tensor[1:]\n",
    "\n",
    "#     total_samples = rest_tensor.shape[0]\n",
    "    \n",
    "#     train_ration = 0.8\n",
    "#     train_length = int(train_ration * total_samples)\n",
    "#     val_length = total_samples - train_length\n",
    "    \n",
    "    \n",
    "#     train_subset, val_subset = random_split(rest_tensor, [train_length, val_length])\n",
    "    \n",
    "    \n",
    "#     # Convert Subset back into tensors\n",
    "#     train_tensor = train_subset.dataset[train_subset.indices]\n",
    "#     val_tensor = val_subset.dataset[val_subset.indices]\n",
    "\n",
    "#     return train_tensor, val_tensor, test_tensor\n",
    "\n",
    "\n",
    "def split_data(data_array):\n",
    "    \"\"\"split ndarray into train, test, vali arrays\n",
    "\n",
    "    Args:\n",
    "        data_array (numpy.ndarray): The input data array.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray, numpy.ndarray, numpy.ndarray: Train, Validation, Test arrays.\n",
    "    \"\"\"\n",
    "    test_array = data_array[0:1]\n",
    "    rest_array = data_array[1:]\n",
    "\n",
    "    total_samples = rest_array.shape[0]\n",
    "    \n",
    "    train_ration = 0.8\n",
    "    train_length = int(train_ration * total_samples)\n",
    "    val_length = total_samples - train_length\n",
    "    \n",
    "    indices = np.arange(total_samples)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_array = rest_array[indices[:train_length]]\n",
    "    val_array = rest_array[indices[train_length:]]\n",
    "\n",
    "    return train_array, val_array, test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## split ndarray data\n",
    "train_data, val_data, test_data = split_data(noisy_data)\n",
    "\n",
    "\n",
    "## add channel dim\n",
    "train_tensor = torch.tensor(train_data[..., np.newaxis, :, :, :], dtype=torch.float32) \n",
    "val_tensor = torch.tensor(val_data[..., np.newaxis, :, :, :], dtype=torch.float32) \n",
    "test_tensor = torch.tensor(test_data[..., np.newaxis, :, :, :], dtype=torch.float32) \n",
    "\n",
    "print(f\"train_tensor:\\n {train_tensor.dtype}; shape:{train_tensor.shape}; range:({torch.min(train_tensor)},{torch.max(train_tensor)}); mean:{torch.mean(train_tensor)}; std:{torch.std(train_tensor)}\")\n",
    "print(f\"val_tensor:\\n {val_tensor.dtype}; shape:{val_tensor.shape}; range:({torch.min(val_tensor)},{torch.max(val_tensor)}); mean:{torch.mean(val_tensor)}; std:{torch.std(val_tensor)}\")\n",
    "print(f\"test_tensor:\\n {test_tensor.dtype}; shape:{test_tensor.shape}; range:({torch.min(test_tensor)},{torch.max(test_tensor)}); mean:{torch.mean(test_tensor)}; std:{torch.std(test_tensor)}\")\n",
    "\n",
    "\n",
    "## create dataset\n",
    "num_mask = 1\n",
    "\n",
    "train_dataset = MaskDataset(train_tensor, num_mask)\n",
    "val_dataset = MaskDataset(val_tensor, num_mask)\n",
    "test_dataset = MaskDataset(test_tensor, num_mask)\n",
    "\n",
    "print(f\"train_dataset: {len(train_dataset)}\")\n",
    "print(f\"val_dataset: {len(val_dataset)}\")\n",
    "print(f\"test_dataset: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "# create dataloader\n",
    "batch_size = 32\n",
    "num_workers = 12\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example batch plot\n",
    "num_batches_to_display = 5  # for example, show 3 batches\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch_idx, (top_slice, mask_middle_slice, bottom_slice, middle_slice) in enumerate(val_loader):\n",
    "    \n",
    "    # Print data details\n",
    "    print(f\"Batch {batch_idx + 1}\")\n",
    "    print(f\"top_slice: {top_slice.dtype} {top_slice.shape} range:({torch.max(top_slice)},{torch.min(top_slice)}); mean:{torch.mean(top_slice)}; std:{torch.std(top_slice)}\")\n",
    "    print(f\"mask_middle_slice: {mask_middle_slice.dtype} {mask_middle_slice.shape} range:({torch.max(mask_middle_slice)},{torch.min(mask_middle_slice)}); mean:{torch.mean(mask_middle_slice)}; std:{torch.std(mask_middle_slice)}\")\n",
    "    print(f\"bottom_slice: {bottom_slice.dtype} {bottom_slice.shape} range:({torch.max(bottom_slice)},{torch.min(bottom_slice)}); mean:{torch.mean(bottom_slice)}; std:{torch.std(bottom_slice)}\")\n",
    "    print(f\"middle_slice: {middle_slice.dtype} {middle_slice.shape} range:({torch.max(middle_slice)},{torch.min(middle_slice)}); mean:{torch.mean(middle_slice)}; std:{torch.std(middle_slice)}\")\n",
    "\n",
    "    # select the show baych index\n",
    "    idx = -1\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(25, 4))\n",
    "\n",
    "    axes[0].imshow(top_slice[idx].squeeze().numpy(), cmap='hot')\n",
    "    axes[0].set_title('Top')\n",
    "\n",
    "    axes[1].imshow(mask_middle_slice[idx].squeeze().numpy(), cmap='hot')\n",
    "    axes[1].set_title('Masked middle')\n",
    "\n",
    "    axes[2].imshow(bottom_slice[idx].squeeze().numpy(), cmap='hot')\n",
    "    axes[2].set_title('Bottom')\n",
    "\n",
    "    axes[3].imshow(middle_slice[idx].squeeze().numpy(), cmap='hot')\n",
    "    axes[3].set_title('True middle')\n",
    "\n",
    "    # Show difference\n",
    "    difference = (mask_middle_slice[idx] != middle_slice[idx]).float().squeeze().numpy()\n",
    "\n",
    "    canvas = np.zeros_like(difference)\n",
    "\n",
    "    # Set the differing pixels to 1\n",
    "    canvas[difference > 0] = 1\n",
    "\n",
    "    axes[4].imshow(canvas, cmap='hot')\n",
    "    axes[4].set_title('Difference positions')\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Break loop after displaying desired number of batches\n",
    "    if batch_idx + 1 == num_batches_to_display:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  define training modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=\"Training\", dynamic_ncols=True)\n",
    "    for top_slice, mask_middle_slice, bottom_slice, middle_slice in pbar:\n",
    "        top_slice, mask_middle_slice, bottom_slice, middle_slice = top_slice.to(device), mask_middle_slice.to(device), bottom_slice.to(device), middle_slice.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(top_slice, mask_middle_slice, bottom_slice)\n",
    "        \n",
    "        # Zero the gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(outputs, middle_slice)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"batch_loss\": loss.item()})\n",
    "    \n",
    "    scheduler.step()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0 \n",
    "    pbar = tqdm(val_loader, desc=\"Validating\", dynamic_ncols=True)\n",
    "    with torch.no_grad():\n",
    "        for top_slice, mask_middle_slice, bottom_slice, middle_slice in pbar:\n",
    "            top_slice, mask_middle_slice, bottom_slice, middle_slice = top_slice.to(device), mask_middle_slice.to(device), bottom_slice.to(device), middle_slice.to(device)\n",
    "            outputs = model(top_slice, mask_middle_slice, bottom_slice)\n",
    "            loss = criterion(outputs, middle_slice)\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({\"batch_loss\": loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "# @timer_decorator\n",
    "# def test(model, test_loader, device):\n",
    "#     model.eval()\n",
    "#     preds = []\n",
    "#     targets = []\n",
    "#     pbar = tqdm(test_loader, desc=\"Testing\", dynamic_ncols=True)\n",
    "#     with torch.no_grad():\n",
    "#         for top_slice, mask_middle_slice, bottom_slice, middle_slice in pbar:\n",
    "#             top_slice, mask_middle_slice, bottom_slice, middle_slice = top_slice.to(device), mask_middle_slice.to(device), bottom_slice.to(device), middle_slice.to(device)\n",
    "            \n",
    "#             pred = model(top_slice, mask_middle_slice, bottom_slice)\n",
    "#             preds.append(pred.cpu()) # predict\n",
    "#             targets.append(middle_slice.cpu()) # original input data\n",
    "            \n",
    "#     return preds, targets\n",
    "# def test(model, test_loader, device, original_shape):\n",
    "#     # 初始化两个全0的tensor用于存放预测和目标\n",
    "#     preds = torch.zeros(original_shape).to(device)\n",
    "#     targets = torch.zeros(original_shape).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     pbar = tqdm(test_loader, desc=\"Testing\", dynamic_ncols=True)\n",
    "#     with torch.no_grad():\n",
    "#         for idx, (top_slice, mask_middle_slice, bottom_slice, middle_slices) in enumerate(pbar):\n",
    "#             top_slice, mask_middle_slice, bottom_slice, middle_slices = top_slice.to(device), mask_middle_slice.to(device), bottom_slice.to(device), middle_slices.to(device)\n",
    "            \n",
    "#             batch_preds = model(top_slice, mask_middle_slice, bottom_slice)\n",
    "            \n",
    "#             for b_idx, pred in enumerate(batch_preds):\n",
    "#                 # 计算应该放置预测值和目标值的位置\n",
    "#                 patience_idx = (idx * len(batch_preds) + b_idx) // (original_shape[1] * (original_shape[3] - 2))\n",
    "#                 time_idx = ((idx * len(batch_preds) + b_idx) % (original_shape[1] * (original_shape[3] - 2))) // (original_shape[3] - 2)\n",
    "#                 depth_idx = (idx * len(batch_preds) + b_idx) % (original_shape[3] - 2) + 1\n",
    "                \n",
    "#                 pred = pred.squeeze(0)\n",
    "#                 middle_slice = middle_slices[b_idx].squeeze(0)\n",
    "                \n",
    "#                 preds[patience_idx, time_idx, :, depth_idx, :, :] = pred\n",
    "#                 targets[patience_idx, time_idx, :, depth_idx, :, :] = middle_slice\n",
    "\n",
    "#     return preds.cpu(), targets.cpu()\n",
    "\n",
    "def test(model, test_loader, device, dataset):\n",
    "    model.eval()\n",
    "    p, t, d = dataset.p, dataset.t, dataset.d\n",
    "    # Note: d represents number of continuous slices after subtracting 2\n",
    "    original_shape = (p, t, dataset.data_tensor.shape[2], d+2, dataset.data_tensor.shape[4], dataset.data_tensor.shape[5])\n",
    "\n",
    "    preds = torch.zeros(original_shape).to(device)\n",
    "    targets = torch.zeros(original_shape).to(device)\n",
    "\n",
    "    pbar = tqdm(test_loader, desc=\"Testing\", dynamic_ncols=True)\n",
    "    with torch.no_grad():\n",
    "        for idx, (top_slice, mask_middle_slice, bottom_slice, middle_slice) in enumerate(pbar):\n",
    "            top_slice, mask_middle_slice, bottom_slice, middle_slice = top_slice.to(device), mask_middle_slice.to(device), bottom_slice.to(device), middle_slice.to(device)\n",
    "            \n",
    "            batch_preds = model(top_slice, mask_middle_slice, bottom_slice)\n",
    "\n",
    "            for b_idx, pred in enumerate(batch_preds):\n",
    "                pred = pred.squeeze(0) # [channels, height, width]\n",
    "                true_idx = idx*test_loader.batch_size + b_idx\n",
    "                patience_idx = true_idx // (t * d)\n",
    "                time_idx = (true_idx % (t * d)) // d\n",
    "                depth_idx = true_idx % d + 1\n",
    "\n",
    "                preds[patience_idx, time_idx, :, depth_idx, :, :] = pred\n",
    "                targets[patience_idx, time_idx, :, depth_idx, :, :] = middle_slice[b_idx]\n",
    "\n",
    "    return preds.cpu(), targets.cpu()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@timer_decorator\n",
    "def train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=50, patience=5, save_path='path/to/your/directory'):\n",
    "    best_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "    best_epoch = -1\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, scheduler, device)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.8f}, Validation Loss: {val_loss:.8f}, LR: {current_lr:.8e}\")\n",
    "\n",
    "        # Save the model with the best validation loss\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            best_epoch = epoch + 1  # 1-based counting for epoch\n",
    "            best_save_path = os.path.join(save_path, f'best_model.pth')\n",
    "            torch.save(best_model_wts, best_save_path)\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f\"Early stopping after {patience} epochs without improvement.(epoch {epoch - patience})\")\n",
    "                break\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define loss, optimizer, lr_scheduler\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "#criterion = nn.MSELoss()\n",
    "#criterion = SSIM_MAELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. process training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=200, patience=10, save_path=\"./check_points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. process denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load best model\n",
    "model.load_state_dict(torch.load('check_points/best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# denoising \n",
    "preds, targets = test(model, test_loader, device, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "denoised_data = preds[0].squeeze(1).numpy()\n",
    "true_data = targets[0].squeeze(1).numpy()\n",
    "\n",
    "print(f\"denoised data: {denoised_data.dtype}; shape:{denoised_data.shape}; range:({np.min(denoised_data)},{np.max(denoised_data)}); mean:{np.mean(denoised_data)}; std:{np.std(denoised_data)}\")\n",
    "print(f\"true_data data: {true_data.dtype}; shape:{true_data.shape}; range:({np.min(true_data)},{np.max(true_data)}); mean:{np.mean(true_data)}; std:{np.std(true_data)}\")\n",
    "\n",
    "\n",
    "# example plot\n",
    "data_range_true = np.max(true_data[11, 38]) - np.min(true_data[11, 38])\n",
    "data_range_denoised = np.max(denoised_data[11, 38]) - np.min(denoised_data[11, 38])\n",
    "data_range = max(data_range_true, data_range_denoised)\n",
    "print(f\"data range: {data_range}\")\n",
    "psnr_values, ssim_values, mae_values, brisque_values = calculate_metrics(denoised_data[11, 38], true_data[11, 38], data_range=data_range)\n",
    "print(f\"PSNR: {np.nanmean(psnr_values)}; SSIM: {np.nanmean(ssim_values)}; MAE: {np.sum(mae_values)}; BRISQUE: {np.mean(brisque_values)}\")\n",
    "\n",
    "display_image_in_detail(denoised_data[11, 38], title='denoised')\n",
    "display_image_in_detail(true_data[11, 38], title='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. metrics evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_range_true = np.max(true_data) - np.min(true_data)\n",
    "data_range_denoised = np.max(denoised_data) - np.min(denoised_data)\n",
    "data_range = max(data_range_true, data_range_denoised)\n",
    "print(f\"data range: {data_range}\")\n",
    "\n",
    "#\n",
    "psnr_values, ssim_values, mae_values, brisque_values = calculate_metrics(denoised_data, true_data, data_range=data_range)\n",
    "\n",
    "psnr_values[np.isinf(psnr_values)] = np.nan # set inf value to nan\n",
    "\n",
    "print(f\"PSNR: {np.nanmean(psnr_values)}; SSIM: {np.nanmean(ssim_values)}; MAE: {np.sum(mae_values)}; BRISQUE: {np.nanmean(brisque_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save denormalized denoised data into 16-bit DICOM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalized denoised data\n",
    "restored_data = restore_data(denoised_data, restore_info)\n",
    "print(f\"restore_data: {restored_data.dtype} shape:{restored_data.shape}; range:({np.min(restored_data)},{np.max(restored_data)}); mean:{np.mean(restored_data)}; std:{np.std(restored_data)}\")\n",
    "display_image_in_detail(restored_data[11, 38], title=\"restored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save denormalized denoised data as 16-bit gray-scale .DICOM files\n",
    "origin_dicom_folder = './dataset/10_05_2021_PET_only/PT_20p 150_120 OSEM'\n",
    "\n",
    "output_folder = './dataset/denoised/N2V/PT_20p 150_120 OSEM_poisson_0.35'\n",
    "\n",
    "save_4d_dicom(origin_dicom_folder, restored_data, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
