{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise-As-Clean Experiment\n",
    "\n",
    "[Europe PMC: Noisy-As-Clean: Learning Self-supervised Denoising from Corrupted Image](https://europepmc.org/article/med/32997627)\n",
    "\n",
    "Key idea: \n",
    "- **Noise-As-CLean**: Using noisy image as both input and target\n",
    "- **Generalization to Clean Images**: Even though trained with noisy images as target, the network, when presented with a real-world noisy image, generalizes to produce a denoised version, leveraging the structured noise learning.\n",
    "\n",
    "Pros: \n",
    "1. **Simplicity**: There's no need for paired noisy-clean datasets. This can significantly simplify the data collection and pre-processing steps.\n",
    "2. **Effectiveness**: In many scenarios, NAC has been found to perform comparably, or sometimes even better than traditional denoising methods, especially when there's a lack of ground-truth clean images.\n",
    "3. **Robustness**: Training on various noise patterns might offer more robustness against different noise types.\n",
    "\n",
    "Cons:\n",
    "1. **Potential Overfitting**: If not implemented carefully, there's a risk that the network might overfit to the specific noise patterns of the training dataset, leading to less optimal performance on real-world or unseen noise distributions.\n",
    "2. **Dependence on Noise Type**: The success of NAC might depend on the type and distribution of noise in the training data. It might not generalize well for all types of noises or for extremely high levels of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from module.utils import calculate_metrics, display_image_in_detail, plot_2d_data, timer_decorator, display_4d_image, timer_decorator\n",
    "from module.datasets import load_4d_dicom, save_4d_dicom, restore_data\n",
    "\n",
    "from module.models import UNet2_5D\n",
    "from module.datasets import NACDataset\n",
    "from module.loss import SSIMLoss, SSIM_MAELoss, SSIM_MSELoss\n",
    "\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load noisy data\n",
    "with h5py.File('./dataset/preprocessed/PT_20p 150_120 OSEM_real_0.00_batch.h5', 'r') as f:\n",
    "    noisy_data = f['dataset'][...]\n",
    "    restore_info = json.loads(f['restore_info'][()])\n",
    "    \n",
    "print(f\"Noisy data...{noisy_data.dtype} (shape:{noisy_data.shape}; range:[{np.min(noisy_data)},{np.max(noisy_data)}]; mean:{np.mean(noisy_data)}); std:{np.std(noisy_data)}\")\n",
    "\n",
    "print(restore_info)\n",
    "\n",
    "display_image_in_detail(noisy_data[0, 11, 38], title=\"prepared noisy data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import denoising network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graphviz_path = r'C:\\Program Files\\Graphviz\\bin'\n",
    "os.environ[\"PATH\"] += os.pathsep + graphviz_path\n",
    "\n",
    "from torchviz import make_dot\n",
    "\n",
    "model = UNet2_5D(in_channels=3, out_channels=1)\n",
    "x_top = torch.randn(1, 1, 192, 192)\n",
    "x_middle = torch.randn(1, 1, 192, 192)\n",
    "x_bottom = torch.randn(1, 1, 192, 192)\n",
    "\n",
    "output = model(x_top, x_middle, x_bottom)\n",
    "\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "dot.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. create NAC dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def split_tensor(data_tensor):\n",
    "#     \"\"\"split tensor into train, test, vali tensor\n",
    "\n",
    "#     Args:\n",
    "#         data_tensor (_type_): _description_\n",
    "\n",
    "#     Returns:\n",
    "#         _type_: _description_\n",
    "#     \"\"\"\n",
    "#     test_tensor = data_tensor[0:1]\n",
    "    \n",
    "#     rest_tensor = data_tensor[1:]\n",
    "\n",
    "#     total_samples = rest_tensor.shape[0]\n",
    "    \n",
    "#     train_ration = 0.8\n",
    "#     train_length = int(train_ration * total_samples)\n",
    "#     val_length = total_samples - train_length\n",
    "    \n",
    "    \n",
    "#     train_subset, val_subset = random_split(rest_tensor, [train_length, val_length])\n",
    "    \n",
    "    \n",
    "#     # Convert Subset back into tensors\n",
    "#     train_tensor = train_subset.dataset[train_subset.indices]\n",
    "#     val_tensor = val_subset.dataset[val_subset.indices]\n",
    "\n",
    "#     return train_tensor, val_tensor, test_tensor\n",
    "\n",
    "\n",
    "def split_data(data_array):\n",
    "    \"\"\"split ndarray into train, test, vali arrays\n",
    "\n",
    "    Args:\n",
    "        data_array (numpy.ndarray): The input data array.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray, numpy.ndarray, numpy.ndarray: Train, Validation, Test arrays.\n",
    "    \"\"\"\n",
    "    test_array = data_array[0:1]\n",
    "    rest_array = data_array[1:]\n",
    "\n",
    "    total_samples = rest_array.shape[0]\n",
    "    \n",
    "    train_ration = 0.8\n",
    "    train_length = int(train_ration * total_samples)\n",
    "    val_length = total_samples - train_length\n",
    "    \n",
    "    indices = np.arange(total_samples)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_array = rest_array[indices[:train_length]]\n",
    "    val_array = rest_array[indices[train_length:]]\n",
    "\n",
    "    return train_array, val_array, test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## split ndarray data\n",
    "train_data, val_data, test_data = split_data(noisy_data)\n",
    "\n",
    "\n",
    "## add channel dim\n",
    "train_tensor = torch.tensor(train_data[..., np.newaxis, :, :, :], dtype=torch.float32) \n",
    "val_tensor = torch.tensor(val_data[..., np.newaxis, :, :, :], dtype=torch.float32) \n",
    "test_tensor = torch.tensor(test_data[..., np.newaxis, :, :, :], dtype=torch.float32) \n",
    "\n",
    "print(f\"train_tensor:\\n {train_tensor.dtype}; shape:{train_tensor.shape}; range:({torch.min(train_tensor)},{torch.max(train_tensor)}); mean:{torch.mean(train_tensor)}; std:{torch.std(train_tensor)}\")\n",
    "print(f\"val_tensor:\\n {val_tensor.dtype}; shape:{val_tensor.shape}; range:({torch.min(val_tensor)},{torch.max(val_tensor)}); mean:{torch.mean(val_tensor)}; std:{torch.std(val_tensor)}\")\n",
    "print(f\"test_tensor:\\n {test_tensor.dtype}; shape:{test_tensor.shape}; range:({torch.min(test_tensor)},{torch.max(test_tensor)}); mean:{torch.mean(test_tensor)}; std:{torch.std(test_tensor)}\")\n",
    "\n",
    "\n",
    "## create dataset\n",
    "train_dataset = NACDataset(train_tensor)\n",
    "val_dataset = NACDataset(val_tensor)\n",
    "test_dataset = NACDataset(test_tensor)\n",
    "\n",
    "print(f\"train_dataset: {len(train_dataset)}\")\n",
    "print(f\"val_dataset: {len(val_dataset)}\")\n",
    "print(f\"test_dataset: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "# create dataloader\n",
    "batch_size = 32\n",
    "num_workers = 12\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example batch plot\n",
    "num_batches_to_display = 5  # for example, show 3 batches\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch_idx, (top_slice, middle_slice, bottom_slice, middle_target) in enumerate(train_loader):\n",
    "    \n",
    "    # Print data details\n",
    "    print(f\"Batch {batch_idx + 1}\")\n",
    "    print(f\"top_slice: {top_slice.dtype} {top_slice.shape} range:({torch.max(top_slice)},{torch.min(top_slice)}); mean:{torch.mean(top_slice)}; std:{torch.std(top_slice)}\")\n",
    "    print(f\"middle_slice: {middle_slice.dtype} {middle_slice.shape} range:({torch.max(middle_slice)},{torch.min(middle_slice)}); mean:{torch.mean(middle_slice)}; std:{torch.std(middle_slice)}\")\n",
    "    print(f\"bottom_slice: {bottom_slice.dtype} {bottom_slice.shape} range:({torch.max(bottom_slice)},{torch.min(bottom_slice)}); mean:{torch.mean(bottom_slice)}; std:{torch.std(bottom_slice)}\")\n",
    "    print(f\"middle_target: {middle_target.dtype} {middle_target.shape} range:({torch.max(middle_target)},{torch.min(middle_target)}); mean:{torch.mean(middle_target)}; std:{torch.std(middle_target)}\")\n",
    "\n",
    "    # select the show baych index\n",
    "    idx = -1\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "\n",
    "    axes[0].imshow(top_slice[idx].squeeze().numpy(), cmap='hot')\n",
    "    axes[0].set_title('Top')\n",
    "\n",
    "    axes[1].imshow(middle_slice[idx].squeeze().numpy(), cmap='hot')\n",
    "    axes[1].set_title('Middle')\n",
    "\n",
    "    axes[2].imshow(bottom_slice[idx].squeeze().numpy(), cmap='hot')\n",
    "    axes[2].set_title('Bottom')\n",
    "\n",
    "    axes[3].imshow(middle_target[idx].squeeze().numpy(), cmap='hot')\n",
    "    axes[3].set_title('Middle Target')\n",
    "\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Break loop after displaying desired number of batches\n",
    "    if batch_idx + 1 == num_batches_to_display:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  define training modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=\"Training\", dynamic_ncols=True)\n",
    "    for top_slice, middle_slice, bottom_slice, middle_target in pbar:\n",
    "        \n",
    "        top_slice, middle_slice, bottom_slice, middle_target = top_slice.to(device), middle_slice.to(device), bottom_slice.to(device), middle_target.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(top_slice, middle_slice, bottom_slice)\n",
    "        \n",
    "        # Zero the gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(outputs, middle_target)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"batch_loss\": loss.item()})\n",
    "    \n",
    "    scheduler.step()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0 \n",
    "    pbar = tqdm(val_loader, desc=\"Validating\", dynamic_ncols=True)\n",
    "    with torch.no_grad():\n",
    "        for top_slice, middle_slice, bottom_slice, middle_target in pbar:\n",
    "            \n",
    "            top_slice, middle_slice, bottom_slice, middle_target = top_slice.to(device), middle_slice.to(device), bottom_slice.to(device), middle_target.to(device)\n",
    "            \n",
    "            outputs = model(top_slice, middle_slice, bottom_slice)\n",
    "            \n",
    "            loss = criterion(outputs, middle_target)\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({\"batch_loss\": loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "# @timer_decorator\n",
    "# def test(model, test_loader, device):\n",
    "#     model.eval()\n",
    "#     preds = []\n",
    "#     targets = []\n",
    "#     pbar = tqdm(test_loader, desc=\"Testing\", dynamic_ncols=True)\n",
    "#     with torch.no_grad():\n",
    "#         for top_slice, mask_middle_slice, bottom_slice, middle_slice in pbar:\n",
    "#             top_slice, mask_middle_slice, bottom_slice, middle_slice = top_slice.to(device), mask_middle_slice.to(device), bottom_slice.to(device), middle_slice.to(device)\n",
    "            \n",
    "#             pred = model(top_slice, mask_middle_slice, bottom_slice)\n",
    "#             preds.append(pred.cpu()) # predict\n",
    "#             targets.append(middle_slice.cpu()) # original input data\n",
    "            \n",
    "#     return preds, targets\n",
    "# def test(model, test_loader, device, original_shape):\n",
    "#     # 初始化两个全0的tensor用于存放预测和目标\n",
    "#     preds = torch.zeros(original_shape).to(device)\n",
    "#     targets = torch.zeros(original_shape).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     pbar = tqdm(test_loader, desc=\"Testing\", dynamic_ncols=True)\n",
    "#     with torch.no_grad():\n",
    "#         for idx, (top_slice, mask_middle_slice, bottom_slice, middle_slices) in enumerate(pbar):\n",
    "#             top_slice, mask_middle_slice, bottom_slice, middle_slices = top_slice.to(device), mask_middle_slice.to(device), bottom_slice.to(device), middle_slices.to(device)\n",
    "            \n",
    "#             batch_preds = model(top_slice, mask_middle_slice, bottom_slice)\n",
    "            \n",
    "#             for b_idx, pred in enumerate(batch_preds):\n",
    "#                 # 计算应该放置预测值和目标值的位置\n",
    "#                 patience_idx = (idx * len(batch_preds) + b_idx) // (original_shape[1] * (original_shape[3] - 2))\n",
    "#                 time_idx = ((idx * len(batch_preds) + b_idx) % (original_shape[1] * (original_shape[3] - 2))) // (original_shape[3] - 2)\n",
    "#                 depth_idx = (idx * len(batch_preds) + b_idx) % (original_shape[3] - 2) + 1\n",
    "                \n",
    "#                 pred = pred.squeeze(0)\n",
    "#                 middle_slice = middle_slices[b_idx].squeeze(0)\n",
    "                \n",
    "#                 preds[patience_idx, time_idx, :, depth_idx, :, :] = pred\n",
    "#                 targets[patience_idx, time_idx, :, depth_idx, :, :] = middle_slice\n",
    "\n",
    "#     return preds.cpu(), targets.cpu()\n",
    "\n",
    "def test(model, test_loader, device, dataset):\n",
    "    model.eval()\n",
    "    p, t, d = dataset.p, dataset.t, dataset.d\n",
    "    # Note: d represents number of continuous slices after subtracting 2\n",
    "    original_shape = (p, t, dataset.data_tensor.shape[2], d+2, dataset.data_tensor.shape[4], dataset.data_tensor.shape[5])\n",
    "\n",
    "    preds = torch.zeros(original_shape).to(device)\n",
    "    targets = torch.zeros(original_shape).to(device)\n",
    "\n",
    "    pbar = tqdm(test_loader, desc=\"Testing\", dynamic_ncols=True)\n",
    "    with torch.no_grad():\n",
    "        for idx, (top_slice, middle_slice, bottom_slice, middle_target) in enumerate(pbar):\n",
    "            \n",
    "            top_slice, middle_slice, bottom_slice, middle_target = top_slice.to(device), middle_slice.to(device), bottom_slice.to(device), middle_target.to(device)\n",
    "            \n",
    "            batch_preds = model(top_slice, middle_slice, bottom_slice)\n",
    "\n",
    "            for b_idx, pred in enumerate(batch_preds):\n",
    "                pred = pred.squeeze(0) # [channels, height, width]\n",
    "                true_idx = idx*test_loader.batch_size + b_idx\n",
    "                patience_idx = true_idx // (t * d)\n",
    "                time_idx = (true_idx % (t * d)) // d\n",
    "                depth_idx = true_idx % d + 1\n",
    "\n",
    "                preds[patience_idx, time_idx, :, depth_idx, :, :] = pred\n",
    "                targets[patience_idx, time_idx, :, depth_idx, :, :] = middle_target[b_idx]\n",
    "\n",
    "    return preds.cpu(), targets.cpu()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@timer_decorator\n",
    "def train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=50, patience=5, save_path='path/to/your/directory'):\n",
    "    best_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "    best_epoch = -1\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, scheduler, device)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.8f}, Validation Loss: {val_loss:.8f}, LR: {current_lr:.8e}\")\n",
    "\n",
    "        # Save the model with the best validation loss\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            best_epoch = epoch + 1  # 1-based counting for epoch\n",
    "            best_save_path = os.path.join(save_path, f'best_model.pth')\n",
    "            torch.save(best_model_wts, best_save_path)\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f\"Early stopping after {patience} epochs without improvement epoch:{epoch}.\")\n",
    "                break\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define loss, optimizer, lr_scheduler\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "#criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. process training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_model = train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=200, patience=10, save_path=\"./check_points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. process denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load best model\n",
    "model.load_state_dict(torch.load('check_points/best_model_epoch_42.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# denoising \n",
    "preds, targets = test(model, test_loader, device, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "denoised_data = preds[0].squeeze(1).numpy()\n",
    "true_data = targets[0].squeeze(1).numpy()\n",
    "\n",
    "print(f\"denoised data: {denoised_data.dtype}; shape:{denoised_data.shape}; range:({np.min(denoised_data)},{np.max(denoised_data)}); mean:{np.mean(denoised_data)}; std:{np.std(denoised_data)}\")\n",
    "print(f\"true_data data: {true_data.dtype}; shape:{true_data.shape}; range:({np.min(true_data)},{np.max(true_data)}); mean:{np.mean(true_data)}; std:{np.std(true_data)}\")\n",
    "\n",
    "\n",
    "# example plot\n",
    "data_range_true = np.max(true_data[11, 38]) - np.min(true_data[11, 38])\n",
    "data_range_denoised = np.max(denoised_data[11, 38]) - np.min(denoised_data[11, 38])\n",
    "data_range = max(data_range_true, data_range_denoised)\n",
    "print(f\"data range: {data_range}\")\n",
    "psnr_values, ssim_values, mae_values, brisque_values = calculate_metrics(denoised_data[11, 38], true_data[11, 38], data_range=data_range)\n",
    "print(f\"PSNR: {np.nanmean(psnr_values)}; SSIM: {np.nanmean(ssim_values)}; MAE: {np.sum(mae_values)}; BRISQUE: {np.mean(brisque_values)}\")\n",
    "\n",
    "display_image_in_detail(denoised_data[11, 38], title='denoised')\n",
    "display_image_in_detail(true_data[11, 38], title='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. metrics evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_range_true = np.max(true_data) - np.min(true_data)\n",
    "data_range_denoised = np.max(denoised_data) - np.min(denoised_data)\n",
    "data_range = max(data_range_true, data_range_denoised)\n",
    "print(f\"data range: {data_range}\")\n",
    "\n",
    "#\n",
    "psnr_values, ssim_values, mae_values, brisque_values = calculate_metrics(denoised_data, true_data, data_range=data_range)\n",
    "\n",
    "psnr_values[np.isinf(psnr_values)] = np.nan # set inf value to nan\n",
    "\n",
    "print(f\"PSNR: {np.nanmean(psnr_values)}; SSIM: {np.nanmean(ssim_values)}; MAE: {np.sum(mae_values)}; BRISQUE: {np.nanmean(brisque_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save denormalized denoised data into 16-bit DICOM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalized denoised data\n",
    "restored_data = restore_data(denoised_data, restore_info)\n",
    "print(f\"restore_data: {restored_data.dtype} shape:{restored_data.shape}; range:({np.min(restored_data)},{np.max(restored_data)}); mean:{np.mean(restored_data)}; std:{np.std(restored_data)}\")\n",
    "display_4d_image(restored_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save denormalized denoised data as 16-bit gray-scale .DICOM files\n",
    "origin_dicom_folder = './dataset/10_05_2021_PET_only/PT_20p 150_120 OSEM'\n",
    "\n",
    "output_folder = './dataset/denoised/NAC/PT_20p 150_120 OSEM_real_0.00_batch'\n",
    "\n",
    "save_4d_dicom(origin_dicom_folder, restored_data, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
