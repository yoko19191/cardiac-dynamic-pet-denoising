{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise2Void Experiment\n",
    "\n",
    "[CVPR 2019 : Noise2Void - Learning Denoising from Single Noisy Image](https://openaccess.thecvf.com/content_CVPR_2019/papers/Krull_Noise2Void_-_Learning_Denoising_From_Single_Noisy_Images_CVPR_2019_paper.pdf)\n",
    "\n",
    "Key idea: \n",
    "- Blind-spot network(BSN), network learn the mapping between mask pixel(s) and every other pixels\n",
    "- the expect of output identical to clean image when noise mean is zero and i.i.d and there traing data inf.\n",
    "\n",
    "Pros: \n",
    "1. single noisy image denoising, has tremendous practicality on medical denoising task\n",
    "2. can adaptive to any noise distribution since its learn denoising directly from noisy image \n",
    "\n",
    "Cons:\n",
    "1. by masking certain pixel(s), the quality of denoising decrease, especially for high-frequency content\n",
    "2. strong assumption of zero mean noise and pixels i.i.d, leading to poor performance when it dealing with structured noise \n",
    "3. denoising performance slightly degrade to N2N but still better than BM3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from module.utils import calculate_metrics, display_image_in_detail, plot_2d_data, timer_decorator, display_4d_image, timer_decorator\n",
    "from module.datasets import load_4d_dicom, save_4d_dicom, restore_data\n",
    "\n",
    "from module.models import UNet2_5D\n",
    "from module.datasets import MaskDataset\n",
    "\n",
    "\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load noisy data\n",
    "with h5py.File('./dataset/preprocessed/PT_20p 150_120 OSEM_real_0.00_batch.h5', 'r') as f:\n",
    "    noisy_data = f['dataset'][...]\n",
    "    restore_info = json.loads(f['restore_info'][()])\n",
    "    \n",
    "print(f\"Noisy data...{noisy_data.dtype} (shape:{noisy_data.shape}; range:[{np.min(noisy_data)},{np.max(noisy_data)}]; mean:{np.mean(noisy_data)}); std:{np.std(noisy_data)}\")\n",
    "\n",
    "print(restore_info)\n",
    "\n",
    "display_image_in_detail(noisy_data[0, 11, 38], title=\"prepared noisy data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Denoising"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import denoising network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = UNet2_5D(in_channels=3, out_channels=1)\n",
    "model = model.to(device)\n",
    "print(\"The number of parameters of the network is: \",  sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "summary(model, [(1, 192, 192), (1, 192, 192), (1, 192, 192)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. create mask dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_tensor(data_tensor):\n",
    "    \"\"\"split tensor into train, test, vali tensor\n",
    "\n",
    "    Args:\n",
    "        data_tensor (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    test_tensor = data_tensor[0:1]\n",
    "    \n",
    "    rest_tensor = data_tensor[1:]\n",
    "\n",
    "    total_samples = rest_tensor.shape[0]\n",
    "    \n",
    "    train_ration = 0.8\n",
    "    train_length = int(train_ration * total_samples)\n",
    "    val_length = total_samples - train_length\n",
    "    \n",
    "    train_tensor, val_tensor = random_split(rest_tensor, [train_length, val_length])\n",
    "\n",
    "    return train_tensor.dataset, val_tensor.dataset, test_tensor\n",
    "\n",
    "\n",
    "# convert to ndarray to tensor\n",
    "noisy_tensor = torch.tensor(noisy_data[:, :, np.newaxis, :, :, :], dtype=torch.float32) \n",
    "noisy_tensor = noisy_tensor.to(device)\n",
    "print(f\"noisy_tensor\\n shape: {noisy_tensor.shape}; range:({torch.min(noisy_tensor)},{torch.max(noisy_tensor)}) ;mean:{torch.mean(noisy_tensor)}; std:{torch.std(noisy_tensor)} \") # (batch, time, channel, depth, height, width\n",
    "\n",
    "\n",
    "# create dataset\n",
    "\n",
    "train_tensor, val_tensor, test_tensor = split_tensor(noisy_tensor) # split input tensor \n",
    "\n",
    "num_masks = 1\n",
    "\n",
    "train_dataset = MaskDataset(train_tensor, num_masks)\n",
    "val_dataset = MaskDataset(val_tensor, num_masks)\n",
    "test_dataset = MaskDataset(test_tensor, num_masks)\n",
    "\n",
    "\n",
    "# create dataloader\n",
    "batch_size = 32\n",
    "num_workers = 12\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example dataloader feed\n",
    "top_slice, mask_middle_slice, bottom_slice, middle_slice = next(iter(train_loader))\n",
    "\n",
    "print(f\"top_slice: {top_slice.dtype} {top_slice.shape} range:({torch.max(top_slice)},{torch.min(top_slice)}); mean:{torch.mean(top_slice)}; std:{torch.std(top_slice)}\")\n",
    "print(f\"mask_middle_slice: {mask_middle_slice.dtype} {mask_middle_slice.shape} range:({torch.max(mask_middle_slice)},{torch.min(mask_middle_slice)}); mean:{torch.mean(mask_middle_slice)}; std:{torch.std(mask_middle_slice)}\")\n",
    "print(f\"bottom_slice: {bottom_slice.dtype} {bottom_slice.shape} range:({torch.max(bottom_slice)},{torch.min(bottom_slice)}); mean:{torch.mean(bottom_slice)}; std:{torch.std(bottom_slice)}\")\n",
    "print(f\"middle_slice: {middle_slice.dtype} {middle_slice.shape} range:({torch.max(middle_slice)},{torch.min(middle_slice)}); mean:{torch.mean(middle_slice)}; std:{torch.std(middle_slice)}\")\n",
    "\n",
    "# select the show baych index\n",
    "idx = 1\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(25, 4))\n",
    "\n",
    "axes[0].imshow(top_slice[idx].squeeze().cpu().numpy(), cmap='hot')\n",
    "axes[0].set_title('Top')\n",
    "\n",
    "axes[1].imshow(mask_middle_slice[idx].squeeze().cpu().numpy(), cmap='hot')\n",
    "axes[1].set_title('Masked middle')\n",
    "\n",
    "axes[2].imshow(bottom_slice[idx].squeeze().cpu().numpy(), cmap='hot')\n",
    "axes[2].set_title('Bottom')\n",
    "\n",
    "axes[3].imshow(middle_slice[idx].squeeze().cpu().numpy(), cmap='hot')\n",
    "axes[3].set_title('True middle')\n",
    "\n",
    "#\n",
    "difference = (mask_middle_slice[idx] != middle_slice[idx]).float().squeeze().cpu().numpy()\n",
    "axes[4].imshow(difference, cmap='hot')\n",
    "axes[4].set_title('mask position')\n",
    "    \n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  define training modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=\"Training\", dynamic_ncols=True)\n",
    "    for top_slice, mask_middle_slice, bottom_slice, middle_slice in train_loader:\n",
    "        #top_slice, mask_middle_slice, bottom_slice, middle_slice = top_slice.to(device), mask_middle_slice.to(device), bottom_slice.to(device), middle_slice.to(device)\n",
    "        # Forward\n",
    "        outputs = model(top_slice, mask_middle_slice, bottom_slice)\n",
    "        loss = criterion(outputs, middle_slice)\n",
    "        # Backward\n",
    "        optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"batch_loss\": loss.item()})\n",
    "    \n",
    "    scheduler.step()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0 \n",
    "    pbar = tqdm(val_loader, desc=\"Validating\", dynamic_ncols=True)\n",
    "    with torch.no_grad():\n",
    "        for top_slice, mask_middle_slice, bottom_slice, middle_slice in pbar:\n",
    "            #top_slice, mask_middle_slice, bottom_slice, middle_slice = top_slice.to(device), mask_middle_slice.to(device), bottom_slice.to(device), middle_slice.to(device)\n",
    "            outputs = model(top_slice, mask_middle_slice, bottom_slice)\n",
    "            loss = criterion(outputs, middle_slice)\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({\"batch_loss\": loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "@timer_decorator\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    pbar = tqdm(test_loader, desc=\"Testing\", dynamic_ncols=True)\n",
    "    with torch.no_grad():\n",
    "        for top_slice, mask_middle_slice, bottom_slice, middle_slice in pbar:\n",
    "            #top_slice, mask_middle_slice, bottom_slice, middle_slice = top_slice.to(device), mask_middle_slice.to(device), bottom_slice.to(device), middle_slice.to(device)\n",
    "            \n",
    "            pred = model(top_slice, mask_middle_slice, bottom_slice)\n",
    "            preds.append(pred.cpu()) # predict\n",
    "            targets.append(middle_slice.cpu()) # original input data\n",
    "            \n",
    "    return preds, targets\n",
    "\n",
    "\n",
    "@timer_decorator\n",
    "def train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=50, patience=5, save_path='path/to/your/directory'):\n",
    "    best_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "    best_epoch = -1\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, scheduler, device)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save the model with the best validation loss\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            best_epoch = epoch + 1  # 1-based counting for epoch\n",
    "            best_save_path = os.path.join(save_path, f'best_model_epoch_{best_epoch}.pth')\n",
    "            torch.save(best_model_wts, best_save_path)\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f\"Early stopping after {patience} epochs without improvement.\")\n",
    "                break\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss, optimizer, lr_scheduler\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.7)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. process training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_model = train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=200, patience=10, save_path=\"./check_points\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. process denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load best model\n",
    "best_model = model.load_state_dict(torch.load('check_points/best_model_epoch_30.pth'))\n",
    "\n",
    "# denoising \n",
    "denoised_tensor = test(model, test_loader, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. metrics evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save denormalized denoised data into 16-bit DICOM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalized denoised data\n",
    "restored_data = restore_data(denoised_data, restore_info)\n",
    "print(f\"restore_data: {restored_data.dtype} shape:{restored_data.shape}; range:({np.min(restored_data)},{np.max(restored_data)}); mean:{np.mean(restored_data)}; std:{np.std(restored_data)}\")\n",
    "display_4d_image(restored_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save denormalized denoised data as 16-bit gray-scale .DICOM files\n",
    "origin_dicom_folder = './dataset/10_05_2021_PET_only/PT_20p 150_120 OSEM'\n",
    "\n",
    "output_folder = './dataset/denoised/BM4D/PT_20p 150_120 OSEM_real_0.00_batch'\n",
    "\n",
    "save_4d_dicom(origin_dicom_folder, restored_data, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
